{
    "version": "https://jsonfeed.org/version/1",
    "title": "MikeMao's blog • All posts by \"爬虫\" tag",
    "description": "a student of NJU who use this website to record learning experience",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2023/01/25/python%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0/",
            "url": "http://example.com/2023/01/25/python%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0/",
            "title": "python爬虫学习",
            "date_published": "2023-01-25T03:21:52.000Z",
            "content_html": "<h1 id=\"python爬虫学习总结\"><a class=\"anchor\" href=\"#python爬虫学习总结\">#</a> python 爬虫学习总结</h1>\n<p>学习 python 爬虫的一些笔记</p>\n<p><span id=\"more\"></span></p>\n<h2 id=\"requests模块\"><a class=\"anchor\" href=\"#requests模块\">#</a> requests 模块</h2>\n<p>requests 模块流程：</p>\n<pre><code>1. 指定url\n2. 发起请求 response = requests.get(url)\n3. 获取数据 page_source = response.text()\n4. 存储数据 文件操作/数据库操作\n</code></pre>\n<p>参数 tips：params 是用来发送查询字符串，而 data 是用来发送正文的。post 与 get 方法的特性是：这两种参数 post（）方法都可以用，get 方法只能发查询字符串，不能发送正文</p>\n<p>text 返回字符串 content 返回二进制（爬取图片可用）  json 返回对象</p>\n<p>分页爬取：</p>\n<p>​\t如果是 ajax，在检查、网络、xhr 中查看</p>\n<p>​\t如果是新链接，可以使用正则表达式匹配 url</p>\n<p>如果是用 ajax 的包：要注意的：</p>\n<ul>\n<li>看请求方法 是 GET 还是 POST。。。</li>\n<li>看响应头的 content-type 选择 reponse.text () 或 reponse.json ()</li>\n<li>看负载中带的参数</li>\n</ul>\n<p>中文乱码问题（文件编码格式为 utf8 json.dump 时 ensure acill 选项关闭）</p>\n<p>什么是 ajax? （根据用户行为重新渲染界面。 不修改 url 在检查 - 网络 - XHR 中查看具体信息）</p>\n<h2 id=\"bs4-数据解析\"><a class=\"anchor\" href=\"#bs4-数据解析\">#</a> bs4 数据解析</h2>\n<p>bs4 数据解析的原理：</p>\n<p>1. 实例化一个 BeautifulSoup 对象 并且将页面原码数据加载到该对象中</p>\n<p>2. 通过调用 bs 对象中相关的属性或方法进行标签定位和数据提取</p>\n<p>如何实例化 beautifulsoup 对象：</p>\n<ol>\n<li>\n<p>将本地的 html 文档中的数据加载到该对象中</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>fp <span class=\"token operator\">=</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>soup <span class=\"token operator\">=</span> BeautifulSoup<span class=\"token punctuation\">(</span>fp<span class=\"token punctuation\">,</span><span class=\"token string\">'lxml'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n<li>\n<p>将互联网上获取的页面源码加载到该对象中</p>\n<pre><code>page_text = response.text\nsoup = BeautifulSoup(page_text,'lxml')\n</code></pre>\n</li>\n</ol>\n<p>提供的用于数据解析的方法和属性：</p>\n<p>soup.tagname 返回 html 中第一次出现的 tagname 标签</p>\n<p>soup.find ('tagname') 等同于 soup.tagname</p>\n<p>soup.find ('tagname', class = 'classname') 定义属性位置， class 可以替换为 id attr</p>\n<p>soup.find_all ('tagname') 找到符合要求所有标签 返回列表</p>\n<p>soup.select ('.tang')  参数为某种选择器（id class 标签），返回一个列表</p>\n<p>soup.select ('.tang&gt; ul &gt; li &gt; a') 层级选择器，返回一个列表</p>\n<p>soup.selest ('.tang&gt; ul a') &gt; 号表示一个层级，空格表示多个层级</p>\n<p>怎么获取标签之间的文本数据：</p>\n<p>使用\tsoup.a.text/string/get_text () 方法</p>\n<pre><code>-   text/get_text(): 可以获取某一个标签中所有的文本内容（多套几层也能得到）\n-   string：获取标签下直系的文本内容\n</code></pre>\n<p>怎么获取标签的属性值：</p>\n<p><code>soup.select('tang &gt; ul &gt; li &gt; a')[0]['href']</code>  直接获得 a 标签中的 herf 属性值</p>\n<h2 id=\"xpath解析\"><a class=\"anchor\" href=\"#xpath解析\">#</a> xpath 解析</h2>\n<p>xpath 解析： 最常用且最便捷高效的一种解析方式。</p>\n<p>xpath 解析原理：</p>\n<pre><code>1. 实例化一个etree的对象，且需要将被解析的页面源码数据加载到该对象中。\n2. 调用etree对象中的xpath方法结合xpath表达式实现标签的定位和内容的捕获。\n</code></pre>\n<p>环境安装：</p>\n<pre><code>- pip install lxml\n</code></pre>\n<p>如何实例化 etree 对象</p>\n<p>​\tfrom lxml import etree</p>\n<ol>\n<li>\n<p>将本地的 html 文档中的源码数据加载到 etree 对象中：</p>\n<p><code> etree.parse(filePath)</code></p>\n</li>\n<li>\n<p>可以将从互联网上获取的源码数据加载到该对象中</p>\n<p><code>etree.HTML('page_text')        -xpath('xpath表达式')</code></p>\n</li>\n</ol>\n<p>/ 表示一个层级  // 表示多个层级</p>\n<p>路径后加 [@ 属性名] 精确定位 如 <code>xx_list = tree.xpath('//div[@class='song']')</code></p>\n<p>中括号内加数字代表取第几个（索引下标从 1 开始） <code>xx_list[0]</code></p>\n<p>获取文本：定位后加 /text ()</p>\n<h2 id=\"中文出现乱码常见的处理方法\"><a class=\"anchor\" href=\"#中文出现乱码常见的处理方法\">#</a> 中文出现乱码常见的处理方法</h2>\n<p>两种常见方法，一般能解决所有中文乱码问题</p>\n<ol>\n<li>\n<p>对爬下来的整个数据改变编码：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>response<span class=\"token punctuation\">.</span>encoding <span class=\"token operator\">=</span> <span class=\"token string\">'utf-8'</span></pre></td></tr></table></figure></li>\n<li>\n<p>对出现问题的对象单独进行编码与解码</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>img_name <span class=\"token operator\">=</span> img_name<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span><span class=\"token string\">'iso-8859-1'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token string\">'gbk'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n</ol>\n<h2 id=\"selenium模块\"><a class=\"anchor\" href=\"#selenium模块\">#</a> selenium 模块</h2>\n<h3 id=\"selenium模块与爬虫之间具有怎样的关联\"><a class=\"anchor\" href=\"#selenium模块与爬虫之间具有怎样的关联\">#</a> selenium 模块与爬虫之间具有怎样的关联？</h3>\n<ul>\n<li>便捷的获取网站中动态加载的数据</li>\n<li>便捷实现模拟登录</li>\n</ul>\n<h3 id=\"什么是selenium模块\"><a class=\"anchor\" href=\"#什么是selenium模块\">#</a> 什么是 selenium 模块</h3>\n<p>基于浏览器自动化的一个模块。 （编写代码让浏览器完成自动化操作）</p>\n<h3 id=\"selenium使用流程\"><a class=\"anchor\" href=\"#selenium使用流程\">#</a> selenium 使用流程：</h3>\n<ul>\n<li>环境安装：pip install selenium</li>\n<li>下载一个浏览器的驱动程序</li>\n<li>实例化一个浏览器对象</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> selenium <span class=\"token keyword\">import</span> webdriver</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> selenium<span class=\"token punctuation\">.</span>webdriver<span class=\"token punctuation\">.</span>edge<span class=\"token punctuation\">.</span>service <span class=\"token keyword\">import</span> Service</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\"># 实例化一个浏览器对象 参数中的路径为浏览器驱动程序的路径（建议与程序在同一路径下）</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>service <span class=\"token operator\">=</span> Service<span class=\"token punctuation\">(</span>executable_path <span class=\"token operator\">=</span> <span class=\"token string\">'./edgedriver.exe'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>bro <span class=\"token operator\">=</span> webdriver<span class=\"token punctuation\">.</span>Edge<span class=\"token punctuation\">(</span>service <span class=\"token operator\">=</span> service<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><ul>\n<li>编写基于浏览器的代码</li>\n</ul>\n<h3 id=\"selenium常用函数\"><a class=\"anchor\" href=\"#selenium常用函数\">#</a> selenium 常用函数</h3>\n<ul>\n<li>\n<p>bro.get (url)  \t\t\t\t\t\t\t\t\t\t\t让浏览器发起一个指定 url 对应请求</p>\n</li>\n<li>\n<p>page_text = bro.page_source\t\t  获取浏览器当前页面的页面源码数据</p>\n</li>\n<li>\n<p>标签定位：使用 find_element 方法</p>\n</li>\n</ul>\n<p>​\tsearch_input = bro.find_element(By.[attrname], &quot;[attr]'s value&quot;)</p>\n<ul>\n<li>\n<p>标签交互：</p>\n<p>​\tsearch_input.send_keys('xxx')</p>\n</li>\n<li>\n<p>执行一组 js 代码</p>\n<p>​\tbro.execute_script('code...')</p>\n</li>\n<li>\n<p>点击按钮：</p>\n<p>​\tbtn.click()</p>\n</li>\n<li>\n<p>后退 / 前进</p>\n<p>​\tbro.back()/forward()</p>\n</li>\n</ul>\n<h3 id=\"selenium处理iframe\"><a class=\"anchor\" href=\"#selenium处理iframe\">#</a> selenium 处理 iframe</h3>\n<p>bro.switch_to.frame('frame_name')</p>\n<h3 id=\"动作链项目暂时用不到\"><a class=\"anchor\" href=\"#动作链项目暂时用不到\">#</a> 动作链 (项目暂时用不到)</h3>\n<p>南大相关网站的登录还不需要滑块验证</p>\n<p>碰到滑块验证的时候可能就需要用到了</p>\n<h3 id=\"selenium实现模拟登录\"><a class=\"anchor\" href=\"#selenium实现模拟登录\">#</a> selenium 实现模拟登录</h3>\n<p>结合前面的基础知识 先点击账号密码登录按钮，找到账号输入框与密码输入框，</p>\n<p>输入账号密码，点击登录按钮</p>\n<h2 id=\"模拟登陆cookie操作\"><a class=\"anchor\" href=\"#模拟登陆cookie操作\">#</a> 模拟登陆 cookie 操作</h2>\n<h3 id=\"cookie有什么作用\"><a class=\"anchor\" href=\"#cookie有什么作用\">#</a> cookie 有什么作用</h3>\n<p>TCP/IP 协议是无状态的，因此通常的 get 请求 服务器端不知道你有没有处于登录状态</p>\n<p>携带 cookie 值的 get 请求 能使服务器端知道你已经处于登录状态</p>\n<h3 id=\"手动cookie不推荐\"><a class=\"anchor\" href=\"#手动cookie不推荐\">#</a> 手动 cookie（不推荐）</h3>\n<p>登录网站后通过抓包工具手动复制 cookie 值 将 cookie 值封装到 headers 中，写死在程序里</p>\n<p>缺点：cookie 值一段时间后会过期</p>\n<h3 id=\"自动处理\"><a class=\"anchor\" href=\"#自动处理\">#</a> 自动处理</h3>\n<p>cookie 值是如何产生的？既然 cookie 值能让服务器知道你已经处于登录状态，那么理所当然 cookie 值是登录时发送 post 请求后服务器端生成后发送给客户端的</p>\n<p>session 会话对象：</p>\n<p>作用：</p>\n<ol>\n<li>可以进行请求的发送</li>\n<li>如果请求过程中产生了 cookie，则该 cookie 会被自动存储 / 携带在该 session 对象中</li>\n</ol>\n<p>使用：</p>\n<ol>\n<li>\n<p>创建一个 session 对象 ：  <code>session = requests.Session()</code></p>\n</li>\n<li>\n<p>使用 session 对象进行模拟登录 post 请求的发送 (cookie 就会被存储在 session 中)</p>\n</li>\n<li>\n<p>session 对象对个人主页对应的 get 请求进行发送（携带了 cookie）</p>\n</li>\n</ol>\n<p>如果登录找不到 post 请求或遇到问题导致获得不到 cookie：</p>\n<p>​\t适用 selenium 登录后 用下列方法直接取得 cookie:</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>c <span class=\"token operator\">=</span> bro<span class=\"token punctuation\">.</span>get_cookies<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>bro<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>cookies <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 获取 cookie 中的 name 和 value, 转化成 requests 可以使⽤的形式</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">for</span> cookie <span class=\"token keyword\">in</span> c<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    cookies<span class=\"token punctuation\">[</span>cookie<span class=\"token punctuation\">[</span><span class=\"token string\">'name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> cookie<span class=\"token punctuation\">[</span><span class=\"token string\">'value'</span><span class=\"token punctuation\">]</span></pre></td></tr></table></figure><p>然后就能用 cookies 了：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>response <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>url<span class=\"token operator\">=</span>detail_url<span class=\"token punctuation\">,</span> headers<span class=\"token operator\">=</span>headers<span class=\"token punctuation\">,</span> cookies<span class=\"token operator\">=</span>cookies<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h2 id=\"并行爬取异步爬虫\"><a class=\"anchor\" href=\"#并行爬取异步爬虫\">#</a> 并行爬取（异步爬虫）</h2>\n<p>原理：利用进程池实现并行爬取</p>\n<p>使用方法：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> multiprocessing <span class=\"token keyword\">import</span> Pool</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># 创建进程池</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>pool <span class=\"token operator\">=</span> Pool<span class=\"token punctuation\">(</span>processes<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>pool<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>function_name<span class=\"token punctuation\">,</span> iterable<span class=\"token punctuation\">[</span><span class=\"token punctuation\">,</span>chunksize<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p><strong>processes 参数设置注意</strong>：当进程数量大于 CPU 的内核数量时，等待运行的进程会等到其他进程运行完毕让出内核为止。因此，如果 CPU 是单核，就无法进行多进程并行。在使用多进程爬虫之前，我们需要先了解计算机 CPU 的核心数量。这里用到了 multiprocessing:</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> multiprocessing <span class=\"token keyword\">import</span> cpu_count</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>cpu_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>运行结果为 16。</p>\n<p>使用 eg：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>urls <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'https://xjh.haitou.cc/xa/after/page-&#123;&#125;'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">21</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>pool <span class=\"token operator\">=</span> Pool<span class=\"token punctuation\">(</span>processes<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token comment\">#get_xuanjing 为参数是一个 url 的爬虫函数</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>pool<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>get_xuanjiang<span class=\"token punctuation\">,</span>urls<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>pool<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 关闭进程池，不再接受新的进程</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>pool<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 主进程阻塞等待子进程的退出</span></pre></td></tr></table></figure><h2 id=\"有关爬虫的一些问题\"><a class=\"anchor\" href=\"#有关爬虫的一些问题\">#</a> 有关爬虫的一些问题：</h2>\n<ul>\n<li>\n<p>爬下来的文本中带有 &amp; nbsp 在 html 中表示 no breaking space（不自动换行的空格）</p>\n<p>此时可以采用 str.replace (u'\\xa0', '') 来解决 str 为待处理字符串</p>\n</li>\n<li>\n<p>requests 里.text 与 .content 方法的区别：</p>\n<p>两者区别在于，content 中间存的是字节码，而 text 中存的是 Beautifulsoup 根据猜测的编码方式将 content 内容编码成字符串。</p>\n<p>直接输出 content，会发现前面存在 b' 这样的标志，这是字节字符串的标志，而 text 是，没有前面的 b, 对于纯 ascii 码，这两个可以说一模一样，对于其他的文字，需要正确编码才能正常显示。大部分情况建议使用.text，因为显示的是汉字，但有时会显示乱码，这时需要用.content.decode ('utf-8')，中文常用 utf-8 和 GBK，GB2312 等。这样可以手工选择文字编码方式。</p>\n<p>所以简而言之，.text 是现成的字符串，.content 还要编码，但是.text 不是所有时候显示都正常，这是就需要用.content 进行手动编码</p>\n</li>\n<li>\n<p>两种常见方法，一般能解决所有中文乱码问题</p>\n<ol>\n<li>\n<p>对爬下来的整个数据改变编码：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>response<span class=\"token punctuation\">.</span>encoding <span class=\"token operator\">=</span> <span class=\"token string\">'utf-8'</span></pre></td></tr></table></figure></li>\n<li>\n<p>对出现问题的对象单独进行编码与解码</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>img_name <span class=\"token operator\">=</span> img_name<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span><span class=\"token string\">'iso-8859-1'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token string\">'gbk'</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure></li>\n</ol>\n</li>\n</ul>\n",
            "tags": [
                "python",
                "爬虫"
            ]
        }
    ]
}